# !pip install pytubefix -q
# !pip install yt_dlp ffmpeg-python torch whisper requests nest_asyncio -q
# !pip install yt-dlp ffmpeg-python pydub requests nest_asyncio -q

# -------------------------------------------------------------------------

# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏
import os
import sys
import json
import math
import time
import re
import ffmpeg
import requests
import yt_dlp
from pydub import AudioSegment
from IPython.display import clear_output
import nest_asyncio
from pathlib import Path
from typing import List, Dict

nest_asyncio.apply()

# -------------------------------------------------------------------------

# –ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# -------------------------------------------------------------------------

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Deep Infra
DEEPINFRA_API_KEY = "9kScTQSpFJCd6OdxblR8bHjw3iWSPZkV"
WHISPER_API_URL = "https://api.deepinfra.com/v1/inference/openai/whisper-large"
LLM_API_URL = "https://api.deepinfra.com/v1/inference/meta-llama/Meta-Llama-3-70B-Instruct"

# –ü—É—Ç—å –∫ cookies —Ñ–∞–π–ª—É 
COOKIES_PATH = "/content/drive/MyDrive/ds_one/cookies.txt"
VIDEO_URL = "https://youtu.be/ufOiMggc6pw?si=Hj0LN_Rwknk29OOw"
# -------------------------------------------------------------------------
class Config:
    DRIVE_PATH = "/content/drive/MyDrive/ds_one"    # –ü–∞–ø–∫–∞ –Ω–∞ Google Drive –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    TEMP_DIR = "/content/temp"                      # –í—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–ø–∫–∞
    FRAME_RATE = 18                                 # –°–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤/—Å–µ–∫ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
    MAX_AUDIO_SIZE_MB = 5                           # –†–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞ (—É–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –¥–æ–ª–≥–∏—Ö –≤–∏–¥–µ–æ)
    AUDIO_BITRATE = '128k'
    SAMPLE_RATE = 16000
    TRANSCRIBE_RETRIES = 2                          # –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–∏ —Ç–∞–π–º–∞—É—Ç–µ
    TRANSCRIBE_TIMEOUT = 120                        # –°–µ–∫—É–Ω–¥ –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ Whisper

    @classmethod
    def setup(cls):
        os.makedirs(cls.DRIVE_PATH, exist_ok=True)
        os.makedirs(cls.TEMP_DIR, exist_ok=True)

Config.setup()
# -------------------------------------------------------------------------
def convert_to_mp3(input_path: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ WAV –≤ MP3"""
    output_path = Path(input_path).with_suffix(".mp3")
    (
        ffmpeg
        .input(input_path)
        .output(
            str(output_path),
            acodec='libmp3lame',
            audio_bitrate=Config.AUDIO_BITRATE,
            ar=str(Config.SAMPLE_RATE)
        )
        .overwrite_output()
        .run(quiet=True)
    )
    return str(output_path)
# -------------------------------------------------------------------------
def split_audio(input_path: str) -> List[str]:
    """
    –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ MAX_AUDIO_SIZE_MB,
    —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å —Ä–∏—Å–∫ —Ç–∞–π–º–∞—É—Ç–∞ –ø—Ä–∏ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–∞—Ö
    """
    chunk_size = Config.MAX_AUDIO_SIZE_MB * 1024 * 1024
    file_size = os.path.getsize(input_path)

    if file_size <= chunk_size:
        return [input_path]

    audio = AudioSegment.from_file(input_path)
    duration_ms = len(audio)
    chunk_duration_ms = int((chunk_size / file_size) * duration_ms)

    chunks = []
    for i in range(0, math.ceil(duration_ms / chunk_duration_ms)):
        start = i * chunk_duration_ms
        end = min((i+1) * chunk_duration_ms, duration_ms)
        chunk = audio[start:end]
        chunk_path = Path(input_path).with_name(f"{Path(input_path).stem}_part{i}.mp3")
        chunk.export(chunk_path, format="mp3", bitrate=Config.AUDIO_BITRATE)
        chunks.append(str(chunk_path))

    return chunks
# -------------------------------------------------------------------------
def transcribe_chunk(chunk_path: str) -> str:
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ-—Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –Ω–∞ DeepInfra Whisper"""
    headers = {"Authorization": f"Bearer {DEEPINFRA_API_KEY}"}
    for attempt in range(Config.TRANSCRIBE_RETRIES):
        try:
            with open(chunk_path, "rb") as f:
                response = requests.post(
                    WHISPER_API_URL,
                    headers=headers,
                    files={"audio": f},
                    timeout=Config.TRANSCRIBE_TIMEOUT
                )
            if response.status_code == 200:
                # –£—Å–ø–µ—à–Ω–æ
                return response.json().get("text", "")
            else:
                print(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (—Å—Ç–∞—Ç—É—Å {response.status_code}): {response.text}")
                return ""
        except requests.exceptions.ReadTimeout:
            print(f"‚è± –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ {Path(chunk_path).name}. –ü–æ–≤—Ç–æ—Ä {attempt+1}/{Config.TRANSCRIBE_RETRIES}")
            if attempt < Config.TRANSCRIBE_RETRIES - 1:
                time.sleep(5)
                continue
            else:
                print("‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫.")
                return ""
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ {Path(chunk_path).name}: {e}")
            return ""
    return ""
# -------------------------------------------------------------------------
def transcribe_audio(audio_path: str) -> str:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è:
      1. WAV -> MP3
      2. –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —á–∞–Ω–∫–∏
      3. –û—Ç–ø—Ä–∞–≤–∫–∞ –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞ –Ω–∞ Whisper
    """
    mp3_path = convert_to_mp3(audio_path)
    chunks = split_audio(mp3_path)
    full_text_list = []
    for i, chunk_path in enumerate(chunks, 1):
        print(f"üîä –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç {i}/{len(chunks)}: {Path(chunk_path).name}")
        text = transcribe_chunk(chunk_path)
        full_text_list.append(text)
        os.remove(chunk_path)
    return " ".join(full_text_list)
# -------------------------------------------------------------------------
def extract_json_array(text: str) -> List[Dict]:
    """
    –£–¥–∞–ª—è–µ–º –∫–æ–¥-–±–ª–æ–∫–∏ (```...```),
    –∏—â–µ–º JSON-–º–∞—Å—Å–∏–≤ –º–µ–∂–¥—É –ø–µ—Ä–≤–æ–π '[' –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π ']'.
    """
    text_no_code = re.sub(r'```.*?```', '', text, flags=re.DOTALL)
    start_idx = text_no_code.find('[')
    end_idx = text_no_code.rfind(']')
    if start_idx == -1 or end_idx == -1 or start_idx > end_idx:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω –≤–∞–ª–∏–¥–Ω—ã–π JSON-–º–∞—Å—Å–∏–≤ –≤ –æ—Ç–≤–µ—Ç–µ LLM.")
    array_str = text_no_code[start_idx:end_idx+1].strip()
    return json.loads(array_str)

def process_transcription(full_text: str) -> List[Dict]:
    """
    –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM -> JSON —Å key= [start_time, end_time, text]
    """
    prompt = f"""
You are a sports analysis assistant. Analyze the following transcript of a basketball match and extract only the moments when a foul occurred.
Return a valid JSON array of objects. Each object must have exactly these keys:
  "start_time": a number representing the start time in seconds,
  "end_time": a number representing the end time in seconds,
  "text": a string describing the foul.
Do not include any additional text, commentary, or markdown formatting. Your entire answer must be a valid JSON array.

Transcript:
{full_text}
"""
    headers = {
        "Authorization": f"Bearer {DEEPINFRA_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "meta-llama/Meta-Llama-3-70B-Instruct",
        "input": prompt,
        "temperature": 0.3,
        "max_tokens": 2000
    }
    response = requests.post(LLM_API_URL, headers=headers, json=payload)
    if response.status_code != 200:
        print(f"–û—à–∏–±–∫–∞ LLM: {response.status_code}")
        print(response.text)
        return []
    try:
        data = response.json()
        print("LLM API response:", data)
        if "results" in data and isinstance(data["results"], list) and len(data["results"]) > 0:
            result = data["results"][0].get("generated_text", "")
        elif "choices" in data:
            result = data["choices"][0]["message"]["content"]
        elif "result" in data:
            result = data["result"]
        elif "output" in data:
            result = data["output"]
        else:
            raise KeyError("–ù–µ—Ç –∫–ª—é—á–∞ 'results', 'choices', 'result' –∏–ª–∏ 'output' –≤ –æ—Ç–≤–µ—Ç–µ")
        return extract_json_array(result)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        return []
# -------------------------------------------------------------------------
def download_video(url: str) -> str:
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å YouTube (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å cookies)"""
    print("üîÑ –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ...")
    ydl_opts = {
        'format': 'bestvideo+bestaudio/best',
        'outtmpl': os.path.join(Config.TEMP_DIR, '%(title)s.%(ext)s'),
        'merge_output_format': 'mp4',
        'quiet': True,
    }
    if os.path.exists(COOKIES_PATH):
        ydl_opts['cookies'] = COOKIES_PATH
    else:
        print("‚ö† –§–∞–π–ª cookies –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù—É–∂–µ–Ω cookies.txt –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ YouTube (p.s. –Ω—É–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤ –°hrome)")
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            return ydl.prepare_filename(info)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
        sys.exit(1)
# -------------------------------------------------------------------------
def extract_audio(video_path: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ (wav)"""
    audio_path = Path(video_path).with_suffix('.wav')
    (
        ffmpeg
        .input(video_path)
        .output(str(audio_path), acodec='pcm_s16le', ac=1, ar=Config.SAMPLE_RATE)
        .overwrite_output()
        .run(quiet=True)
    )
    return str(audio_path)
# -------------------------------------------------------------------------
def extract_frames_segment(video_path: str, start: float, end: float, idx: int):
    """
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–ª–∞: —Å–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É "foul_{idx}/frames" –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    –∫–∞–¥—Ä—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ –Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ [start, end].
    """
    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ñ–æ–ª–∞
    foul_dir = Path(Config.DRIVE_PATH) / f"foul_{idx}"
    frames_dir = foul_dir / "frames"
    frames_dir.mkdir(parents=True, exist_ok=True)

    try:
        (
            ffmpeg
            .input(video_path, ss=start, to=end)
            .output(str(frames_dir / "frame_%04d.jpg"), r=Config.FRAME_RATE)
            .overwrite_output()
            .run(quiet=True)
        )
        print(f"‚úÖ –ö–∞–¥—Ä—ã —Ñ–æ–ª–∞ #{idx} ({start}-{end}—Å) —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {frames_dir}")
    except ffmpeg.Error as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Ñ–æ–ª–∞ #{idx}: {e.stderr.decode()}")
# -------------------------------------------------------------------------
def process_video(url: str):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å:
      1. –°–∫–∞—á–∏–≤–∞–µ–º –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ
      2. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
      3. LLM -> JSON (—Å–ø–∏—Å–æ–∫ —Ñ–æ–ª–æ–≤)
      4. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–ª–∞: –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã (–±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è .mp4)
    """
    clear_output()
    print("üöÄ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
    try:
        # 1. –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ
        video_path = download_video(url)
        print(f"‚úÖ –í–∏–¥–µ–æ —Å–∫–∞—á–∞–Ω–æ: {Path(video_path).name}")
        
        # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ
        audio_path = extract_audio(video_path)
        print("‚úÖ –ê—É–¥–∏–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ")
        
        # 3. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
        full_text = transcribe_audio(audio_path)
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ-—Ñ–∞–π–ª
        os.remove(audio_path)
        print("‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
        # 4. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM 
        fouls = process_transcription(full_text)
        print(f"üéØ –ù–∞–π–¥–µ–Ω–æ —Ñ–æ–ª–æ–≤: {len(fouls)}")
        
        # 5. –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ñ–æ–ª–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
        for i, foul in enumerate(fouls, start=1):
            start_time = foul.get("start_time", 0)
            end_time   = foul.get("end_time", 0)
            text       = foul.get("text", "")
            
            print(f"\n‚ö° –§–æ–ª #{i}: {start_time}-{end_time} —Å\nüìù {text}")
            extract_frames_segment(video_path, start_time, end_time, i)
        
        print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –ö–∞–¥—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {Config.DRIVE_PATH}")
    
    except Exception as e:
        print(f"üî• –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)
# -------------------------------------------------------------------------
if __name__ == "__main__":
    process_video(VIDEO_URL)
